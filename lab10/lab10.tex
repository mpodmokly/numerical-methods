\documentclass[11pt, leqno]{scrartcl}
\usepackage{polski}
\usepackage[polish]{babel}

\usepackage{graphicx, float, caption, subcaption}
\usepackage{tabularx, multirow, hyperref, enumitem}
\usepackage{listings, xcolor}
\usepackage{amsmath, amssymb}
%\usepackage{minted}

\hypersetup{
    colorlinks=true,
    linkcolor=black,
    urlcolor=black,
    citecolor=black
}

\definecolor{md-black}{rgb}{0.12, 0.12, 0.12}
\definecolor{md-teal}{rgb}{0.38, 0.79, 0.69}
\definecolor{md-mauve}{rgb}{0.76, 0.52, 0.75}
\definecolor{md-yellow}{rgb}{0.86, 0.86, 0.67}
\definecolor{md-green}{rgb}{0.13, 0.55, 0.13}
\definecolor{md-red}{rgb}{0.82, 0.10, 0.14}
\definecolor{md-purple}{rgb}{0.69, 0.33, 0.73}
\definecolor{md-orange}{rgb}{0.96, 0.42, 0.18}
\definecolor{md-gray}{rgb}{0.44, 0.46, 0.51}
\lstset{
    language=Python,
    basicstyle=\color{md-teal}\ttfamily,
    keywordstyle=\color{md-mauve},
    commentstyle=\color{md-green},
    stringstyle=\color{md-red},
    numbers=left,
    numberstyle=\small\color{md-gray}\ttfamily,
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{md-black},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=none,
    tabsize=4,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={\%*}{*)},
    numbersep=-10pt,
    morekeywords={as},
    classoffset=1,
    morekeywords={quad, quad_vec, trapz, simps, linregress,
        newton},
    keywordstyle=\color{md-yellow},
    classoffset=0
}

\graphicspath{{../images/}}

\title{Laboratorium 10 - Równania różniczkowe - spectral bias}
\author{Mateusz Podmokły - II rok Informatyka WI}
\date{28 maj 2024}

\begin{document}
    \maketitle
    \section{Treść zadania}
    \textbf{Zadanie 1.} Dane jest równanie różniczkowe zwyczajne
    \[
        \frac{du(x)}{dx}=cos(\omega x), \quad x \in \Omega
    \]
    gdzie: \\
    $x$, $\omega$, $u \in \mathbb{R}$, \\
    $x$ to położenie, \\
    $\Omega$ to dziedzina, na której rozwiązujemy równanie,
    $\Omega=\{x|-2\pi \leq x \leq 2\pi\}$, \\
    $u(x)$ to funkcja, której postaci szukamy.

    \subsection*{}
    Warunek początkowy zdefiniowany jest następująco:
    \[
        u(0)=0.
    \]
    Analityczna postać rozwiązania równania z warunkiem
    początkowym jest następująca:
    \[
        u(x)=\frac{sin(\omega x)}{\omega}
    \]
    Rozwiąż powyższe zagadnienie początkowe. Do rozwiązania
    użyj sieci neuronowych typu PINN (ang. Physics-informed Neural
    Network). \\
    Koszt rezydualny zdefiniowany jest następująco:
    \[
        \mathcal{L}_r(\theta)=\frac{1}{N}\sum_{i=1}^{N}
            \left| \left| \frac{d\hat{u}(x)}{dx}-cos(\omega x_i)
            \right| \right| ^2,
    \]
    gdzie $N$ jest liczbą punktów kolokacyjnych. \\
    Koszt związany z warunkiem początkowym przyjmuje postać:
    \[
        \mathcal{L}_{IC}(\theta)=||\hat{u}(0)-0||^2.
    \]
    Funkcja kosztu zdefiniowana jest następująco:
    \[
        \mathcal{L}(\theta)=\mathcal{L}_r(\theta)+
            \mathcal{L}_{IC}(\theta).
    \]
    Warstwa wejściowa sieci posiada 1 neuron, reprezentujący
    zmienną $x$. Warstwa wyjściowa także posiada 1 neuron,
    reprezentujący zmienną $\hat{u}(x)$. Uczenie trwa
    przez 50 000 kroków algorytmem Adam ze stałą uczenia równą
    0.001. Jako funkcję aktywacji przyjmij tangens hiperboliczny,
    $tanh(x)$.

    \subsection*{}
    Rozważ następujące przypadki:
    \begin{enumerate}
        \item Przypadek $\omega=1$. \\
            Ustal następujące wartości:
            \begin{itemize}[label=--]
                \item 2 warstwy ukryte, 16 neuronów w każdej
                    warstwie
                \item liczba punktów treningowych: 200
                \item liczba punktów testowych: 1000
            \end{itemize}
        \item Przypadek $\omega=15$. \\
            Ustal następujące wartości:
            \begin{itemize}[label=--]
                \item liczba punktów treningowych:
                    $200 \cdot 15=3000$
                \item liczba punktów testowych: 5000
            \end{itemize}
            Eksperymenty przeprowadź z trzema architekturami
            sieci:
            \begin{itemize}[label=--]
                \item 2 warstwy ukryte, 16 neuronów w każdej
                    warstwie
                \item 4 warstwy ukryte, 64 neurony w każdej
                    warstwie
                \item 5 warstw ukrytych, 128 neuronów w każdej
                    warstwie
            \end{itemize}
        \item Dla wybranej przez siebie sieci porównaj wynik
            z rozwiązaniem, w którym przyjęto, że szukane
            rozwiązanie ($ansatz$) ma postać:
            \[
                \hat{u}(x;\theta)=tanh(\omega x) \cdot
                    NN(x;\theta).
            \]
            Taka postać rozwiązania gwarantuje spełnienie warunku
            $\hat{u}=0$ bez wprowadzania składnika
            $\mathcal{L}_{IC}$ do funkcji kosztu.
    \end{enumerate}

\end{document}
